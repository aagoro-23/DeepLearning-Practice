{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda, nn\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    x.view(6000,1,-1)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "trainset = MNIST ('./data', train=True, download= True, transform= transform)\n",
    "testset = MNIST('./data', train=False, download= True, transform=transform)\n",
    "\n",
    "mnist_train_loader= torch.utils.data.DataLoader(trainset,batch_size=10, shuffle=True, num_workers=2)\n",
    "mnist_test_loader= torch.utils.data.DataLoader(testset,batch_size=10, shuffle=True, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (h1): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (h2): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (h3): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.h1 = nn.Linear(784,500)\n",
    "        self.h2 = nn.Linear(500,500)\n",
    "        self.h3 = nn.Linear(500,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.sigmoid(self.h1(x))\n",
    "        x = F.sigmoid(self.h2(x))\n",
    "        x = F.softmax(self.h3(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 1.652\n",
      "[1, 4000] loss: 1.540\n",
      "[1, 6000] loss: 1.527\n",
      "[2, 2000] loss: 1.517\n",
      "[2, 4000] loss: 1.513\n",
      "[2, 6000] loss: 1.512\n",
      "[3, 2000] loss: 1.505\n",
      "[3, 4000] loss: 1.509\n",
      "[3, 6000] loss: 1.504\n",
      "[4, 2000] loss: 1.499\n",
      "[4, 4000] loss: 1.501\n",
      "[4, 6000] loss: 1.500\n",
      "[5, 2000] loss: 1.496\n",
      "[5, 4000] loss: 1.497\n",
      "[5, 6000] loss: 1.498\n",
      "[6, 2000] loss: 1.495\n",
      "[6, 4000] loss: 1.495\n",
      "[6, 6000] loss: 1.497\n",
      "[7, 2000] loss: 1.494\n",
      "[7, 4000] loss: 1.492\n",
      "[7, 6000] loss: 1.494\n",
      "[8, 2000] loss: 1.491\n",
      "[8, 4000] loss: 1.492\n",
      "[8, 6000] loss: 1.493\n",
      "[9, 2000] loss: 1.491\n",
      "[9, 4000] loss: 1.491\n",
      "[9, 6000] loss: 1.492\n",
      "[10, 2000] loss: 1.489\n",
      "[10, 4000] loss: 1.491\n",
      "[10, 6000] loss: 1.491\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(mnist_train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i %2000 == 1999:\n",
    "            print('[%d,%5d] loss: %.3f'%\n",
    "                 (epoch + 1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:      0     9     8     9\n"
     ]
    }
   ],
   "source": [
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7','8','9')\n",
    "for _, data in enumerate(mnist_test_loader):\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "\n",
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs,1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range (4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for _,data in enumerate(mnist_test_loader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNet(\n",
       "  (conv1): Conv2d(1, 28, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv2): Conv2d(28, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (l1): Linear(in_features=800, out_features=23, bias=True)\n",
       "  (l2): Linear(in_features=23, out_features=40, bias=True)\n",
       "  (l3): Linear(in_features=40, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,28,4)\n",
    "        self.conv2 = nn.Conv2d(28,50,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.l1 = nn.Linear(800, 23)\n",
    "        self.l2 = nn.Linear(23,40)\n",
    "        self.l3 = nn.Linear(40,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.softmax(self.l3(x))\n",
    "        return x\n",
    "cnnet = CNNet()\n",
    "cnnet.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 1.585\n",
      "[1, 4000] loss: 1.508\n",
      "[1, 6000] loss: 1.498\n",
      "[2, 2000] loss: 1.493\n",
      "[2, 4000] loss: 1.493\n",
      "[2, 6000] loss: 1.494\n",
      "[3, 2000] loss: 1.490\n",
      "[3, 4000] loss: 1.489\n",
      "[3, 6000] loss: 1.489\n",
      "[4, 2000] loss: 1.491\n",
      "[4, 4000] loss: 1.489\n",
      "[4, 6000] loss: 1.495\n",
      "[5, 2000] loss: 1.491\n",
      "[5, 4000] loss: 1.487\n",
      "[5, 6000] loss: 1.489\n",
      "[6, 2000] loss: 1.488\n",
      "[6, 4000] loss: 1.485\n",
      "[6, 6000] loss: 1.492\n",
      "[7, 2000] loss: 1.487\n",
      "[7, 4000] loss: 1.489\n",
      "[7, 6000] loss: 1.489\n",
      "[8, 2000] loss: 1.488\n",
      "[8, 4000] loss: 1.485\n",
      "[8, 6000] loss: 1.494\n",
      "[9, 2000] loss: 1.488\n",
      "[9, 4000] loss: 1.491\n",
      "[9, 6000] loss: 1.498\n",
      "[10, 2000] loss: 1.492\n",
      "[10, 4000] loss: 1.493\n",
      "[10, 6000] loss: 1.492\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "cnnetoptim = optim.Adam(cnnet.parameters(), lr=1e-3)\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(mnist_train_loader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        cnnetoptim.zero_grad()\n",
    "        outputs = cnnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        cnnetoptim.step()\n",
    "        running_loss += loss.item()\n",
    "        if i %2000 == 1999:\n",
    "            print('[%d,%5d] loss: %.3f'%\n",
    "                 (epoch + 1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for _,data in enumerate(mnist_test_loader):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = cnnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:      7     0     7     0\n"
     ]
    }
   ],
   "source": [
    "for _, data in enumerate(mnist_test_loader):\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "\n",
    "outputs = cnnet(images)\n",
    "\n",
    "_, predicted = torch.max(outputs,1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range (4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
